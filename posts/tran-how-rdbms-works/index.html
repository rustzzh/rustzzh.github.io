<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><meta http-equiv=x-ua-compatible content="IE=edge, chrome=1"><title>[tran]关系型数据库原理 - zh's blog</title><meta name=Description content="(WIP)通过翻译这篇文章达到精读一遍的效果"><meta property="og:title" content="[tran]关系型数据库原理"><meta property="og:description" content="(WIP)通过翻译这篇文章达到精读一遍的效果"><meta property="og:type" content="article"><meta property="og:url" content="https://rustzzh.github.io/posts/tran-how-rdbms-works/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-05-09T17:35:56+08:00"><meta property="article:modified_time" content="2022-05-12T11:47:29+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="[tran]关系型数据库原理"><meta name=twitter:description content="(WIP)通过翻译这篇文章达到精读一遍的效果"><meta name=application-name content="zh's blog"><meta name=apple-mobile-web-app-title content="zh's blog"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://rustzzh.github.io/posts/tran-how-rdbms-works/><link rel=prev href=https://rustzzh.github.io/posts/cmu15445-db-storage/><link rel=stylesheet href=/lib/normalize/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=/lib/fontawesome-free/all.min.css><link rel=stylesheet href=/lib/animate/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"[tran]关系型数据库原理","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/rustzzh.github.io\/posts\/tran-how-rdbms-works\/"},"genre":"posts","keywords":"db, rdbms","wordcount":11231,"url":"https:\/\/rustzzh.github.io\/posts\/tran-how-rdbms-works\/","datePublished":"2022-05-09T17:35:56+08:00","dateModified":"2022-05-12T11:47:29+00:00","publisher":{"@type":"Organization","name":"zh"},"author":{"@type":"Person","name":"zh"},"description":"(WIP)通过翻译这篇文章达到精读一遍的效果"}</script></head><body header-desktop header-mobile><script type=text/javascript>(window.localStorage&&localStorage.getItem("theme")?localStorage.getItem("theme")==="dark":''==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:''==="dark")&&document.body.setAttribute("theme","dark")</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="zh's blog">zh's blog</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>文章 </a><a class=menu-item href=/tags/>标签 </a><a class=menu-item href=/categories/>分类 </a><a class=menu-item href=/friend/>友链 </a><a class=menu-item href=/about/>关于 </a><span class="menu-item delimiter"></span><a href=javascript:void(0); class="menu-item theme-switch" title=切换主题>
<i class="fas fa-adjust fa-fw"></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="zh's blog">zh's blog</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><a class=menu-item href=/posts/ title>文章</a><a class=menu-item href=/tags/ title>标签</a><a class=menu-item href=/categories/ title>分类</a><a class=menu-item href=/friend/ title>友链</a><a class=menu-item href=/about/ title>关于</a><a href=javascript:void(0); class="menu-item theme-switch" title=切换主题>
<i class="fas fa-adjust fa-fw"></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>目录</h2><div class="toc-content always-active" id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animated flipInX">[tran]关系型数据库原理</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw"></i>zh</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2022-05-09>2022-05-09</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 11231 字&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 23 分钟&nbsp;</div></div><div class="details toc" id=toc-static kept><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fas fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#1-回顾基础>1 回顾基础</a><ul><li><a href=#11-o1-vs-on2>1.1 $O(1)$ vs $O(n^2)$</a><ul><li><a href=#111-概念>1.1.1 概念</a></li><li><a href=#112-例子>1.1.2 例子</a></li><li><a href=#113-更深入一点>1.1.3 更深入一点</a></li></ul></li><li><a href=#12-归并排序>1.2 归并排序</a><ul><li><a href=#121-合并>1.2.1 合并</a></li><li><a href=#122-分治过程>1.2.2 分治过程</a></li><li><a href=#123-排序过程>1.2.3 排序过程</a></li><li><a href=#124-归并排序的强大之处>1.2.4 归并排序的强大之处</a></li></ul></li><li><a href=#13-数组树和哈希表>1.3 数组，树和哈希表</a><ul><li><a href=#131-数组>1.3.1 数组</a></li><li><a href=#132-树和数据库索引>1.3.2 树和数据库索引</a></li><li><a href=#133-哈希表>1.3.3 哈希表</a></li></ul></li></ul></li><li><a href=#2-全局概述>2 全局概述</a></li><li><a href=#3-客户端管理>3 客户端管理</a></li><li><a href=#4-查询管理>4 查询管理</a><ul><li><a href=#41-查询解析>4.1 查询解析</a></li><li><a href=#42-查询重写>4.2 查询重写</a></li><li><a href=#43-统计信息>4.3 统计信息</a></li><li><a href=#44-查询优化器>4.4 查询优化器</a><ul><li><a href=#441-索引>4.4.1 索引</a></li><li><a href=#442-访问路径>4.4.2 访问路径</a></li><li><a href=#443-联结操作>4.4.3 联结操作</a></li><li><a href=#444-简化的案例>4.4.4 简化的案例</a></li><li><a href=#445-动态规划贪心算法和启发式>4.4.5 动态规划、贪心算法和启发式</a></li><li><a href=#446-真正的优化器unimportant-part>4.4.6 真正的优化器(unimportant part)</a></li><li><a href=#447-查询计划缓存>4.4.7 查询计划缓存</a></li></ul></li><li><a href=#45-查询执行>4.5 查询执行</a></li></ul></li><li><a href=#5-数据管理>5 数据管理</a><ul><li><a href=#51-缓存管理>5.1 缓存管理</a><ul><li><a href=#511-预取>5.1.1 预取</a></li><li><a href=#512-缓存替换策略>5.1.2 缓存替换策略</a></li><li><a href=#513-写缓存>5.1.3 写缓存</a></li></ul></li><li><a href=#52-事务管理>5.2 事务管理</a><ul><li><a href=#521-酸了>5.2.1 酸了</a></li><li><a href=#522-并发控制>5.2.2 并发控制</a></li><li><a href=#523-锁管理>5.2.3 锁管理</a></li><li><a href=#524-日志管理>5.2.4 日志管理</a></li></ul></li></ul></li><li><a href=#6-总结>6 总结</a></li></ul></nav></div></div><div class=content id=content><div class="details admonition note open"><div class="details-summary admonition-title"><i class="icon fas fa-pencil-alt fa-fw"></i>注意<i class="details-icon fas fa-angle-right fa-fw"></i></div><div class=details-content><div class=admonition-content><p><a href=http://coding-geek.com/how-databases-work/ target=_blank rel="noopener noreffer">原文在这</a></p><p>由于博主英语水平有限，本篇译文以段落为单元，先英后中展示。</p><p>较之原文省略了一些博主认为可以缺少的图片。</p><p><strong>加粗</strong> 用来表示原文中强调的内容， <em>斜体</em> 用于表示博主的想法。</p></div></div></div><blockquote><p>When it comes to relational databases, I can’t help thinking that something is missing. They’re used everywhere. There are many different databases: from the small and useful SQLite to the powerful Teradata. But, there are only a few articles that explain how a database works. You can google by yourself “how does a relational database work” to see how few results there are. Moreover, those articles are short. Now, if you look for the last trendy technologies (Big Data, NoSQL or JavaScript), you’ll find more in-depth articles explaining how they work.</p></blockquote><p>当谈到关系型数据库的时候，我不禁会想少了点啥。
它们使用广泛。
这里有许多种不同的数据库：从小而实用的SQLite到强大的Teradata。
但是很少有文章介绍一个数据库是怎么工作的。
你可以自己谷歌搜索一下"how does a relational database work"看看有多少有信息的文章。
此外这些文章都很短。
与此同时，你去搜索现在时兴的一些技术(大数据，NoSQL或者JS)，你能找到很多对原理解析很有深度的文章。</p><blockquote><p>Are relational databases too old and too boring to be explained outside of university courses, research papers and books?</p></blockquote><p>是否是因为关系型数据库太过老旧无聊，以至于无法在大学课程、论文以及书籍之外来介绍其原理吗？</p><blockquote><p>As a developer, I HATE using something I don’t understand. And, if databases have been used for 40 years, there must be a reason. Over the years, I’ve spent hundreds of hours to really understand these weird black boxes I use every day. Relational Databases are very interesting because they’re based on useful and reusable concepts. If understanding a database interests you but you’ve never had the time or the will to dig into this wide subject, you should like this article.</p></blockquote><p>作为一个开发者，我痛恨实用那些我不理解的技术。
并且数据库被使用了长达四十多年肯定是有原因的。
这些年来我花了数百小时来真正理解这些我每天都在使用的奇怪黑盒。
关系型数据库是非常有趣的，因为其构建基于一些非常有用并且可以复用的概念之上。
如果你对理解一个数据库有点兴趣但你又没有时间或者没有这个意愿来钻研这个广泛的主题，你会喜欢这篇文章的。</p><blockquote><p>Though the title of this article is explicit, the aim of this article is NOT to understand how to use a database. Therefore, you should already know how to write a simple join query and basic CRUD queries; otherwise you might not understand this article. This is the only thing you need to know, I’ll explain everything else.</p></blockquote><p>尽管标题写的很清楚，但还是要强调的是这篇文章的目的 <strong>不是</strong> 让你理解怎么来使用数据库。
因此，你需要有一些基础知识，例如会写简单的join查询、会基本的增删查改，否则你会看得云里雾里。
除此之外的一切内容都会涵盖在这篇文章中。</p><blockquote><p>I’ll start with some computer science stuff like time complexity. I know that some of you hate this concept but, without it, you can’t understand the cleverness inside a database. Since it’s a huge topic, I’ll focus on what I think is essential: the way a database handles an SQL query. I’ll only present the basic concepts behind a database so that at the end of the article you’ll have a good idea of what’s happening under the hood.</p></blockquote><p>我会从类似时间复杂度这样的计算机概念开始介绍。
我知道你们可能讨厌这类概念，但是如果不讲这些概念你们很难理解数据库内部的高明之处。
因为这是一个很大的话题，我会聚焦于介绍 <strong>数据库处理一条SQL的方法</strong> 这条主线。
我仅会介绍数据库内部的一些基本概念，这样你在读完本文后能对数据库内部究竟干了些啥有一个比较清晰的理解。</p><blockquote><p>Since it’s a long and technical article that involves many algorithms and data structures, take your time to read it. Some concepts are more difficult to understand; you can skip them and still get the overall idea.</p></blockquote><p>因为这是一篇涉及了很多算法和数据结构的技术文章，慢慢读吧。
其中的有些概念可能很难理解，你可以暂时地跳过这些部分，不会影响整体的理解。</p><blockquote><p>For the more knowledgeable of you, this article is more or less divided into 3 parts:</p><ul><li>An overview of low-level and high-level database components</li><li>An overview of the query optimization process</li><li>An overview of the transaction and buffer pool management</li></ul></blockquote><p>为了你们更容易理解，这篇文章可以大致分为三个部分：</p><ul><li>对数据库底层和顶层组件的概述</li><li>对查询优化过程的概述</li><li>对事务和缓存池管理的概述</li></ul><h1 id=1-回顾基础>1 回顾基础</h1><blockquote><p>A long time ago (in a galaxy far, far away….), developers had to know exactly the number of operations they were coding. They knew by heart their algorithms and data structures because they couldn’t afford to waste the CPU and memory of their slow computers.</p></blockquote><p>很久以前(在遥远的银河系)，开发人员需要精确的知道自己写的代码需要进行的操作数。
他们对自己的算法和数据结构了然于心，因为他们无法忍受在其低速电脑上浪费CPU和内存。</p><blockquote><p>In this part, I’ll remind you about some of these concepts because they are essential to understand a database. I’ll also introduce the notion of database index.</p></blockquote><p>在这一部分我会带你重温一下这些概念，因为他们对理解数据库来说至关重要。
同时我会向你介绍 <strong>数据库索引</strong> 的概念。</p><h2 id=11-o1-vs-on2>1.1 $O(1)$ vs $O(n^2)$</h2><blockquote><p>Nowadays, many developers don’t care about time complexity … and they’re right!</p></blockquote><p>现在很多开发者不太关心时间复杂度，正确的！</p><blockquote><p>But when you deal with a large amount of data (I’m not talking about thousands) or if you’re fighting for milliseconds, it becomes critical to understand this concept. And guess what, databases have to deal with both situations! I won’t bore you a long time, just the time to get the idea. This will help us later to understand the concept of cost based optimization.</p></blockquote><p>但是当你处理一个量级很大的数据(这里说的不是千级别的)或需要考虑毫秒级别性能问题时，理解这个概念就变得至关重要了。
你猜怎么着，数据库两种情况都需要处理！
我不会在这部分花费你太多时间，仅仅有一个大体印象即可。
这对接下来理解 <strong>基于开销的性能优化</strong> 很关键。</p><h3 id=111-概念>1.1.1 概念</h3><blockquote><p>The time complexity is used to see how long an algorithm will take for a given amount of data. To describe this complexity, computer scientists use the mathematical big O notation. This notation is used with a function that describes how many operations an algorithm needs for a given amount of input data.</p></blockquote><p><strong>时间复杂度用来描述一个算法对于给定数量级的数据需要花费多久的时间来处理</strong>。
计算机科学家们用大O表示法来描述这种复杂度。
这种表示法通常与函数搭配使用，函数用来描述对于一个给定量级的输入数据这个算法需要进行多少次操作。</p><blockquote><p>For example, when I say “this algorithm is in O( some_function() )”, it means that for a certain amount of data the algorithm needs some_function(a_certain_amount_of_data) operations to do its job.</p></blockquote><p>举例来说，当我说这个算法是 <code>O(some_function())</code> 的时候，表示着对于一个给定的量级的数据，这个算法需要 <code>some_function(a_certain_amount_of_data)</code> 次操作才能执行完毕。</p><blockquote><p>What’s important is not the amount of data but the way the number of operations increases when the amount of data increases. The time complexity doesn’t give the exact number of operations but a good idea.</p></blockquote><p>这里关键点并不是数据的量级，而是 <strong>操作数随数据增长时的增长量</strong> 。
时间复杂度并没有给出具体的操作次数而是描述了一个大致量。</p><figure><a class=lightgallery href=/images/TimeComplexity.png title=/images/TimeComplexity.png data-thumbnail=/images/TimeComplexity.png data-sub-html="<h2>时间复杂度</h2>"><img class=lazyload src=/svg/loading.min.svg data-src=/images/TimeComplexity.png data-srcset="/images/TimeComplexity.png, /images/TimeComplexity.png 1.5x, /images/TimeComplexity.png 2x" data-sizes=auto alt=/images/TimeComplexity.png height=1500 width=1500></a><figcaption class=image-caption>时间复杂度</figcaption></figure><blockquote><p>In this figure, you can see the evolution of different types of complexities. I used a logarithmic scale to plot it. In other words, the number of data is quickly increasing from 1 to 1 billion. We can see that:</p><ul><li>The O(1) or constant complexity stays constant (otherwise it wouldn’t be called constant complexity).</li><li>The O(log(n)) stays low even with billions of data.</li><li>The worst complexity is the O(n2) where the number of operations quickly explodes.</li><li>The two other complexities are quickly increasing.</li></ul></blockquote><p>在上面的图片中可以看到不同类型复杂度的演化。使用的是对数刻度。
换言之，数据的量级从1到10亿快速增长。
我们可以看到：</p><ul><li><div id=id-1><strong>$O(1)$</strong> 或者说常量复杂度随着数据量增长保持常量(不然它也不会叫常量复杂度)</div></li><li><div id=id-2><strong>$O(log(n))$</strong> 即使在十亿的数据量下操作增长也很慢</div></li><li><div id=id-3>最差的复杂度是 <strong>$O(n^2)$</strong> ，操作的数量爆炸增长</div></li><li>其他两种复杂度增长迅速</li></ul><h3 id=112-例子>1.1.2 例子</h3><blockquote><p>With a low amount of data, the difference between O(1) and O(n2) is negligible. For example, let’s say you have an algorithm that needs to process 2000 elements.</p><ul><li>An $O(1)$ algorithm will cost you 1 operation</li><li>An $O(log(n))$ algorithm will cost you 7 operations</li><li>An $O(n)$ algorithm will cost you 2 000 operations</li><li>An $O(n*log(n))$ algorithm will cost you 14 000 operations</li><li>An $O(n^2)$ algorithm will cost you 4 000 000 operations</li></ul></blockquote><p>在数据很少的时候，$O(1)$和$O(n^2)$的差距可以忽略。举个例子，当一个算法需要处理2000个元素的时候。</p><ul><li>$O(1)$的算法需要进行 1 次操作</li><li>$O(log(n))$的算法需要进行 7 次操作</li><li>$O(n)$的算法需要进行 2 000 次操作</li><li>$O(n*log(n))$的算法需要进行 14 000 次操作</li><li>$O(n^2)$的算法需要进行 4 000 000 次操作</li></ul><blockquote><p>The difference between $O(1)$ and $O(n^2)$ seems a lot (4 million) but you’ll lose at max 2 ms, just the time to blink your eyes. Indeed, current processors can handle hundreds of millions of operations per second. This is why performance and optimization are not an issue in many IT projects.</p></blockquote><p>这里的$O(1)$和$O(n^2)$看起来差距很大(4 000 000 : 1)但是性能损耗最大2ms，一眨眼的功夫。
现在的处理器(本文写于2015年)每秒可以进行数十亿次操作。
这就是为什么在很多IT项目中性能和优化并不是主要问题。</p><blockquote><p>As I said, it’s still important to know this concept when facing a huge number of data. If this time the algorithm needs to process 1 000 000 elements (which is not that big for a database):</p><ul><li>An $O(1)$ algorithm will cost you 1 operation</li><li>An $O(log(n))$ algorithm will cost you 14 operations</li><li>An $O(n)$ algorithm will cost you 1 000 000 operations</li><li>An $O(n*log(n))$ algorithm will cost you 14 000 000 operations</li><li>An $O(n^2)$ algorithm will cost you 1 000 000 000 000 operations</li></ul></blockquote><p>如我所说，当面对一个量级相当大的数据时，时间复杂度的概念就相当重要了。
如果这次这个算法需要处理一百万个元素(对数据库来说这个数量级都还不算大)：</p><ul><li>$O(1)$的算法需要进行 1 次操作</li><li>$O(log(n))$的算法需要进行 14 次操作</li><li>$O(n)$的算法需要进行 1 000 000 次操作</li><li>$O(n*log(n))$的算法需要进行 14 000 000次操作</li><li>$O(n^2)$的算法需要进行 1 000 000 000 000 次操作</li></ul><blockquote><p>I didn’t do the math but I’d say with the $O(n2)$ algorithm you have the time to take a coffee (even a second one!). If you put another 0 on the amount of data, you’ll have the time to take a long nap.</p></blockquote><p>我没有具体算过，但是这一次$O(n^2)$的算法都够你喝杯咖啡了(甚至喝两杯！)如果数量级再加个0，甚至能睡个午觉。</p><h3 id=113-更深入一点>1.1.3 更深入一点</h3><blockquote><p>To give you an idea:</p><ul><li>A search in a good hash table gives an element in O(1)</li><li>A search in a well-balanced tree gives a result in O(log(n))</li><li>A search in an array gives a result in O(n)</li><li>The best sorting algorithms have an O(n*log(n)) complexity.</li><li>A bad sorting algorithm has an O(n2) complexity</li></ul></blockquote><p>为了让你对时间复杂度的有一个大致的印象：</p><ul><li>在一个比较好的哈希表中执行查找的时间复杂度是$O(1)$</li><li>在一个平衡地很好的树中执行查找的时间复杂度是$O(log(n))$</li><li>在数组中执行查找的时间复杂度是$O(n)$</li><li>最好的排序算法时间复杂度是$O(n*log(s))$</li><li>捞的排序算法时间复杂度是$O(n^2)$</li></ul><blockquote><p>Note: In the next parts, we’ll see these algorithms and data structures.</p></blockquote><p>注：下一小节就会看一下这些算法喝数据结构。</p><blockquote><p>There are multiple types of time complexity:</p><ul><li>the average case scenario</li><li>the best case scenario</li><li>and the worst case scenario</li></ul></blockquote><p>关于时间复杂度有几种类型：</p><ul><li>平均的时间复杂度</li><li>最好的情况对应的复杂度</li><li>最坏的情况对应的复杂度</li></ul><blockquote><p>The time complexity is often the worst case scenario.</p></blockquote><p>一个算法的时间复杂度通常指的是最坏情况的时间复杂度。</p><blockquote><p>I only talked about time complexity but complexity also works for:</p><ul><li>the memory consumption of an algorithm</li><li>the disk I/O consumption of an algorithm</li></ul></blockquote><p>这里我只谈到了时间复杂度，复杂度同样适合于描述：</p><ul><li>一个算法的内存开销</li><li>一个算法的磁盘IO开销</li></ul><blockquote><p>Of course there are worse complexities than $n^2$, like:</p><ul><li>$n^4$: that sucks! Some of the algorithms I’ll mention have this complexity.</li><li>$3^n$: that sucks even more! One of the algorithms we’re going to see in the middle of this article has this complexity (and it’s really used in many databases).</li><li>factorial n : you’ll never get your results, even with a low amount of data.</li><li>$n^n$: if you end-up with this complexity, you should ask yourself if IT is really your field…</li></ul></blockquote><p>当然还有比$n^2$更捞的时间复杂度，如下：</p><ul><li>$n^4$：捞得不谈，有的算法是这个时间复杂度。</li><li>$3^n$：捞得淌口水，文章中部有一个算法是这个复杂度。</li><li>$n!$：时间的尽头。</li><li>$n^n$：如果你写出这样的时间复杂度的算法，只能说一眼顶真，鉴定为不适合写代码。</li></ul><p><em>读到这里的朋友不妨自己写一个$n^n$的算法试试</em></p><blockquote><p>Note: I didn’t give you the real definition of the big O notation but just the idea. You can read this article on Wikipedia for the real (asymptotic) definition.</p></blockquote><p>注：这里我并没有给出关于大O表示法的严谨定义。你可以通过<a href=https://en.wikipedia.org/wiki/Big_O_notation target=_blank rel="noopener noreffer">wikipedia</a>看看更准确的定义。</p><h2 id=12-归并排序>1.2 归并排序</h2><blockquote><p>What do you do when you need to sort a collection? What? You call the sort() function … ok, good answer… But for a database you have to understand how this sort() function works.</p></blockquote><p>当你需要一个有序的元素集的时候需要干些啥呢？啥？你调用<code>sort()</code>&mldr;彳亍，好回答&mldr;但是对于数据库来说需要理解<code>sort()</code>是怎么运行的。</p><blockquote><p>There are several good sorting algorithms so I’ll focus on the most important one: the merge sort. You might not understand right now why sorting data is useful but you should after the part on query optimization. Moreover, understanding the merge sort will help us later to understand a common database join operation called the merge join.</p></blockquote><p>有很多不错的排序算法，这里聚焦于介绍 <strong>归并排序</strong> 。
可能现在你不知道为什么排序算法为什么重要，但看完查询优化那一节之后你应该就理解了。
除此之外，理解归并排序有助于我们之后来理解数据库中的一种常见操作：<strong>合并联结</strong>。</p><h3 id=121-合并>1.2.1 合并</h3><blockquote><p>Like many useful algorithms, the merge sort is based on a trick: merging 2 sorted arrays of size N/2 into a N-element sorted array only costs N operations. This operation is called a merge.</p></blockquote><p>像很多使用的算法一样，归并排序是基于这样一个点：将两个长度为 N/2 的有序数据合并成一个长度为 N 的有序数组只需要 N 次操作。
这个操作叫做 <strong>合并</strong>。</p><blockquote><p>Let’s see what this means with a simple example:</p></blockquote><p>看个例子：</p><figure><a class=lightgallery href=/images/merge_sort_3.png title=/images/merge_sort_3.png data-thumbnail=/images/merge_sort_3.png data-sub-html="<h2>归并</h2>"><img class=lazyload src=/svg/loading.min.svg data-src=/images/merge_sort_3.png data-srcset="/images/merge_sort_3.png, /images/merge_sort_3.png 1.5x, /images/merge_sort_3.png 2x" data-sizes=auto alt=/images/merge_sort_3.png height=500 width=500></a><figcaption class=image-caption>归并</figcaption></figure><blockquote><p>You can see on this figure that to construct the final sorted array of 8 elements, you only need to iterate one time in the 2 4-element arrays. Since both 4-element arrays are already sorted:</p><ol><li>you compare both current elements in the 2 arrays (current=first for the first time)</li><li>then take the lowest one to put it in the 8-element array</li><li>and go to the next element in the array you took the lowest element
and repeat 1,2,3 until you reach the last element of one of the arrays.</li></ol><p>Then you take the rest of the elements of the other array to put them in the 8-element array.</p></blockquote><p>从图片中能看到想要得到一个有序的 8 个元素的数组，需要遍历 2 个有序的 4 元素数组，因为这 2 个数组都是有序的：</p><ol><li>两个数组都从头遍历起，每次遍历比较当前二者的大小</li><li>将更小的那个数据塞入到 8 元素数组中</li><li>将第 2 步取数据的数组的遍历指针往后移一位，重复 1,2,3 步直到遍历完某一个数组</li></ol><p>将剩余的元素依次塞入这个 8 元素的数组。</p><blockquote><p>This works because both 4-element arrays are sorted and therefore you don’t need to “go back” in these arrays.</p></blockquote><p>这样行得通的原因是 2 个 4 元素的数组都是有序的，所以无需在这些数组中“回溯”。</p><blockquote><p>Now that we’ve understood this trick, here is my pseudocode of the merge sort.</p></blockquote><p>现在我们已经理解了这个技巧，下面是归并排序的伪代码</p><pre tabindex=0><code>array mergeSort(array a)
   if(length(a)==1)
      return a[0];
   end if
 
   //recursive calls
   [left_array right_array] := split_into_2_equally_sized_arrays(a);
   array new_left_array := mergeSort(left_array);
   array new_right_array := mergeSort(right_array);
 
   //merging the 2 small ordered arrays into a big one
   array result := merge(new_left_array,new_right_array);
   return result;
</code></pre><blockquote><p>The merge sort breaks the problem into smaller problems then finds the results of the smaller problems to get the result of the initial problem (note: this kind of algorithms is called divide and conquer). If you don’t understand this algorithm, don’t worry; I didn’t understand it the first time I saw it. If it can help you, I see this algorithm as a two-phase algorithm:</p><ul><li>The division phase where the array is divided into smaller arrays</li><li>The sorting phase where the small arrays are put together (using the merge) to form a bigger array.</li></ul></blockquote><p>归并排序把问题拆成很多子问题，然后通过解决子问题然后获得最初的大问题的答案(注：这种类型的算法又称为分治算法)。
如果不懂没关系；我第一次看的时候也没看懂。
或许这种解释可以帮助你理解，将其拆分成两个阶段理解：</p><ol><li>拆分阶段：数组被拆分成更小的数组</li><li>排序阶段：小数组被合并成一个大数组</li></ol><h3 id=122-分治过程>1.2.2 分治过程</h3><figure><a class=lightgallery href=/images/merge_sort_1.png title=/images/merge_sort_1.png data-thumbnail=/images/merge_sort_1.png data-sub-html="<h2>拆分</h2>"><img class=lazyload src=/svg/loading.min.svg data-src=/images/merge_sort_1.png data-srcset="/images/merge_sort_1.png, /images/merge_sort_1.png 1.5x, /images/merge_sort_1.png 2x" data-sizes=auto alt=/images/merge_sort_1.png height=500 width=500></a><figcaption class=image-caption>拆分</figcaption></figure><blockquote><p>During the division phase, the array is divided into unitary arrays using 3 steps. The formal number of steps is log(N) (since N=8, log(N) = 3).</p></blockquote><p>在拆分阶段，数组在 3 步内被拆分成单元素的数组。拆分的次数是$log(N)$。</p><blockquote><p>How do I know that?
<del>I’m a genius!</del> In one word: mathematics. The idea is that each step divides the size of the initial array by 2. The number of steps is the number of times you can divide the initial array by two. This is the exact definition of logarithm (in base 2).</p></blockquote><p>我怎么知道的？</p><p><del>我又不是天才</del>！简而言之：数学定义。因为每一步都是将数组拆分成原始数组的 1/2 。因此总步数就是最初的数组能被 2 除以的次数。正好是以2为底的对数的定义。</p><h3 id=123-排序过程>1.2.3 排序过程</h3><figure><a class=lightgallery href=/images/merge_sort_2.png title=/images/merge_sort_2.png data-thumbnail=/images/merge_sort_2.png data-sub-html="<h2>排序</h2>"><img class=lazyload src=/svg/loading.min.svg data-src=/images/merge_sort_2.png data-srcset="/images/merge_sort_2.png, /images/merge_sort_2.png 1.5x, /images/merge_sort_2.png 2x" data-sizes=auto alt=/images/merge_sort_2.png height=500 width=500></a><figcaption class=image-caption>排序</figcaption></figure><blockquote><p>In the sorting phase, you start with the unitary arrays. During each step, you apply multiple merges and the overall cost is N=8 operations:</p><ul><li>In the first step you have 4 merges that cost 2 operations each</li><li>In the second step you have 2 merges that cost 4 operations each</li><li>In the third step you have 1 merge that costs 8 operations</li></ul><p>Since there are log(N) steps, the overall costs N * log(N) operations</p></blockquote><p>在排序阶段，从单个元素的数组开始。在每一步中你需要运行多次合并，并且总合并次数是 N=8 次：</p><ul><li>第一步需要进行 4 次合并，每次需要执行 2 次操作</li><li>第二步需要进行 2 次合并，每次需要执行 4 次操作</li><li>第三步需要执行 1 次合并，每次需要执行 8 次操作</li></ul><p>总共 log(N) 步，因此总开销是 <strong>N * log(N)</strong> 次操作。</p><h3 id=124-归并排序的强大之处>1.2.4 归并排序的强大之处</h3><blockquote><p>Why this algorithm is so powerful?</p></blockquote><p>为什么这个算法这么猛？</p><blockquote><p>Because:</p><ul><li>You can modify it in order to reduce the memory footprint, in a way that you don’t create new arrays but you directly modify the input array.</li></ul><p>Note: this kind of algorithms is called in-place.</p><ul><li>You can modify it in order to use disk space and a small amount of memory at the same time without a huge disk I/O penalty. The idea is to load in memory only the parts that are currently processed. This is important when you need to sort a multi-gigabyte table with only a memory buffer of 100 megabytes.</li></ul><p>Note: this kind of algorithms is called external sorting.</p><ul><li>You can modify it to run on multiple processes/threads/servers.
For example, the distributed merge sort is one of the key components of Hadoop (which is THE framework in Big Data).</li><li>This algorithm can turn lead into gold (true fact!).</li></ul></blockquote><p>因为：</p><ul><li>你可以通过一点修改来减少其内存开销，实现方式为不再创建新数组而是直接修改原数组。</li></ul><p>注：这种算法被称为<a href=https://en.wikipedia.org/wiki/In-place_algorithm target=_blank rel="noopener noreffer">就地算法</a></p><ul><li>你可以将其改为同时使用磁盘和一小部分内存的方式来避免磁盘IO的巨额开销。这种方式每次仅将当前正在处理的部分读入内存。当需要对一个几GB的大表排序，而内存缓存只有 100 MB时特别有用。</li></ul><p>注：这种算法称作<a href=https://en.wikipedia.org/wiki/External_sorting target=_blank rel="noopener noreffer">外部排序</a>。</p><ul><li>你可以将这个算法改成在多个处理器/线程/服务器上同时运行的。</li></ul><p>例如分布式归并排序就是<a href=https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/Reducer.html target=_blank rel="noopener noreffer">Hadoop</a>(大数据框架)的一个关键组件。</p><ul><li>这种算法可以点石成金(触读的)</li></ul><blockquote><p>This sorting algorithm is used in most (if not all) databases but it’s not the only one. If you want to know more, you can read this research paper that discusses the pros and cons of the common sorting algorithms in a database.</p></blockquote><p>这个算法被用在大多数(但不是全部)数据库上，除了这个算法外还有其他的也被用到了。
如果了解更多关于排序算法在数据库中的应用，你可以读一下<a href=http://wwwlgis.informatik.uni-kl.de/archiv/wwwdvs.informatik.uni-kl.de/courses/DBSREAL/SS2005/Vorlesungsunterlagen/Implementing_Sorting.pdf target=_blank rel="noopener noreffer">这篇研究报告</a>，
在报告中讨论了数据库中常见的几种排序算法的优缺点。</p><h2 id=13-数组树和哈希表>1.3 数组，树和哈希表</h2><blockquote><p>Now that we understand the idea behind time complexity and sorting, I have to tell you about 3 data structures. It’s important because they’re the backbone of modern databases. I’ll also introduce the notion of database index.</p></blockquote><p>至此我们讨论完了时间复杂度和排序，接下来要介绍的是三种数据结构。这些数据结构都是现代数据库的支柱，因此相当重要。
这一节同样会介绍数据库索引的概念。</p><h3 id=131-数组>1.3.1 数组</h3><blockquote><p>The two-dimensional array is the simplest data structure. A table can be seen as an array. For example:</p></blockquote><p>二维数组是最简单的数据结构。一张表就可以被看作一个二维数组，如下图所示：</p><figure><a class=lightgallery href=/images/array.png title=/images/array.png data-thumbnail=/images/array.png data-sub-html="<h2>数组</h2>"><img class=lazyload src=/svg/loading.min.svg data-src=/images/array.png data-srcset="/images/array.png, /images/array.png 1.5x, /images/array.png 2x" data-sizes=auto alt=/images/array.png height=500 width=500></a><figcaption class=image-caption>数组</figcaption></figure><blockquote><p>This 2-dimensional array is a table with rows and columns:</p><ul><li>Each row represents a subject</li><li>The columns the features that describe the subjects.</li><li>Each column stores a certain type of data (integer, string, date …).</li></ul></blockquote><p>二维数组是一个有着行、列的表：</p><ul><li>每一行表示一个主体</li><li>每一列标示一个主体的某个特征</li><li>每一列存储着一个特定的数据类型(整型，字符串，日期&mldr;)</li></ul><blockquote><p>Though it’s great to store and visualize data, when you need to look for a specific value it sucks.</p></blockquote><p>尽管这样存储数据非常直观，但当你想要查找一个特定数据的时候很恶心。</p><blockquote><p>For example, if you want to find all the guys who work in the UK, you’ll have to look at each row to find if the row belongs to the UK. This will cost you N operations (N being the number of rows) which is not bad but could there be a faster way? This is where trees come into play.</p></blockquote><p>例如，<strong>你想找到所有在UK工作的人</strong>，你需要逐行查看这一行是否属于UK。<strong>这个操作的时间复杂度是O(N)</strong>，虽然不是太慢，但是还可以更快。这就是接下来要介绍的树要干的事。</p><h3 id=132-树和数据库索引>1.3.2 树和数据库索引</h3><blockquote><p>A binary search tree is a binary tree with a special property, the key in each node must be:</p><ul><li>greater than all keys stored in the left sub-tree</li><li>smaller than all keys stored in the right sub-tree</li></ul></blockquote><p>二分搜索树是一种特定的二叉树，每个节点满足如下特性：</p><ul><li>比左子树所有的节点的值大</li><li>比右子树所有的节点要小</li></ul><figure><a class=lightgallery href=/images/BST.png title=/images/BST.png data-thumbnail=/images/BST.png data-sub-html="<h2>一颗理想的二分查找树</h2>"><img class=lazyload src=/svg/loading.min.svg data-src=/images/BST.png data-srcset="/images/BST.png, /images/BST.png 1.5x, /images/BST.png 2x" data-sizes=auto alt=/images/BST.png height=500 width=500></a><figcaption class=image-caption>一颗理想的二分查找树</figcaption></figure><blockquote><p>This tree has N=15 elements. Let’s say I’m looking for 208:</p><ul><li>I start with the root whose key is 136. Since 136&lt;208, I look at the right sub-tree of the node 136.</li><li>398>208 so, I look at the left sub-tree of the node 398</li><li>250>208 so, I look at the left sub-tree of the node 250</li><li>200&lt;208 so, I look at the right sub-tree of the node 200. But 200 doesn’t have a right subtree, the value doesn’t exist (because if it did exist it would be in the right subtree of 200)</li></ul></blockquote><p>这棵树有 N=15 个元素。比如说我现在要找值为208的元素：</p><ul><li>从根节点136开始。因为136比208小，所以到右子树去。</li><li>398>208，所以到398的左子树</li><li>250>208，所以到250的左子树</li><li>200&lt;208，所以尝试寻找200的右子树，但是200没有右子树，证明208 <strong>不在这棵树</strong> 中(因为如果存在的话它会出现在200的右子树中)。</li></ul><blockquote><p>Now let’s say I’m looking for 40</p><ul><li>I start with the root whose key is 136. Since 136>40, I look at the left sub-tree of the node 136.</li><li>80>40 so, I look at the left sub-tree of the node 80</li><li>40= 40, the node exists. I extract the id of the row inside the node (it’s not in the figure) and look at the table for the given row id.</li><li>Knowing the row id let me know where the data is precisely on the table and therefore I can get it instantly.</li></ul></blockquote><p>现在来找40:</p><ul><li>136>40，去左子树</li><li>80>40，去左子树</li><li>40==40，<strong>节点存在</strong>。从其中取出行id，并到表中查询相应的行。</li><li>因为知道了行id相当于知道了行在表中的具体位置，所以此时取数据很快。</li></ul><blockquote><p>In the end, both searches cost me the number of levels inside the tree. If you read carefully the part on the merge sort you should see that there are log(N) levels. So the cost of the search is log(N), not bad!</p></blockquote><p>可以看到，这两次查询的开销都是树高。
如果你在归并排序那一章读得比较仔细的你应该会发现树高是 log(N).
所以查询的开销是 log(N)，还不错。</p><blockquote><p>Back to our problem
But this stuff is very abstract so let’s go back to our problem. Instead of a stupid integer, imagine the string that represents the country of someone in the previous table. Suppose you have a tree that contains the column “country” of the table:</p><ul><li>If you want to know who is working in the UK</li><li>you look at the tree to get the node that represents the UK</li><li>inside the “UK node” you’ll find the locations of the rows of the UK workers.</li></ul></blockquote><p><strong>回到之前的问题</strong></p><p>但这个数据结构对如何解决开头提到的问题(找到所有在UK工作的人)十分抽象。只需要将树中存储的值换成一个表示某个人工作城市的字符串即可。
假设你有一颗存储着表中“城市”列值的树：</p><ul><li>如果你想知道谁在UK工作</li><li>在树中查找代表着UK的节点</li><li>在“UK节点”中你会找到在UK工作的人的信息在表中的位置</li></ul><blockquote><p>This search only costs you log(N) operations instead of N operations if you directly use the array. What you’ve just imagined was a database index.</p></blockquote><p>这个搜索仅仅需要log(N)次操作，而你如果直接去表中查需要N次。
这就是<strong>数据库索引</strong>。</p><blockquote><p>You can build a tree index for any group of columns (a string, an integer, 2 strings, an integer and a string, a date …) as long as you have a function to compare the keys (i.e. the group of columns) so that you can establish an order among the keys (which is the case for any basic types in a database).</p></blockquote><p>你可以为任何的列组构建这样的树索引(一个字符串、一个整数、两个字符串、一个整数和一个字符串、时间等等)只要你能提供一个比较函数来对这个列组进行排序，基于这个排序能够在这些键中建立起索引树。</p><p><strong>B+树索引</strong></p><blockquote><p>Although this tree works well to get a specific value, there is a BIG problem when you need to get multiple elements between two values. It will cost O(N) because you’ll have to look at each node in the tree and check if it’s between these 2 values (for example, with an in-order traversal of the tree). Moreover this operation is not disk I/O friendly since you’ll have to read the full tree. We need to find a way to efficiently do a range query. To answer this problem, modern databases use a modified version of the previous tree called B+Tree. In a B+Tree:</p><ul><li>only the lowest nodes (the leaves) store information (the location of the rows in the associated table)</li><li>the other nodes are just here to route to the right node during the search.</li></ul></blockquote><p>尽管这个树在单点查询的时候还不赖，但需要获取 <strong>两个值之间的所有元素</strong> 的时候会遇到大问题。
范围查询时的时间复杂度是 O(N)，因为你需要遍历整棵树来看这个节点是不是在两个值之间(例如对树进行中序遍历)。
除此之外，这个操作也不是磁盘IO友好型的，因为需要把整棵树都读到内存。
我们需要找到一种高效执行 <strong>范围查询</strong> 的方式。
为了解决这个问题，现代数据库使用了一种更高级的二叉搜索树：B+树。
在B+树中：</p><ul><li>只有叶子结点真正 <strong>存储信息</strong></li><li>其他节点(根、中间节点)只是在搜索中起 <strong>路由</strong> 作用。</li></ul><figure><a class=lightgallery href=/images/database_index.png title=/images/database_index.png data-thumbnail=/images/database_index.png data-sub-html="<h2>数据库索引</h2>"><img class=lazyload src=/svg/loading.min.svg data-src=/images/database_index.png data-srcset="/images/database_index.png, /images/database_index.png 1.5x, /images/database_index.png 2x" data-sizes=auto alt=/images/database_index.png height=500 width=500></a><figcaption class=image-caption>数据库索引</figcaption></figure><blockquote><p>As you can see, there are more nodes (twice more). Indeed, you have additional nodes, the “decision nodes” that will help you to find the right node (that stores the location of the rows in the associated table). But the search complexity is still in O(log(N)) (there is just one more level). The big difference is that the lowest nodes are linked to their successors.</p></blockquote><p>如图所示，节点更多了(两倍多)。确实，除数据节点外多了很多“决策节点”，这些决策节点帮你找到正确的信息节点。
但是搜索的复杂度仍然是 log(N)，只多了一层。
最大的区别是各个叶子结点可以看成有序链表。</p><blockquote><p>With this B+Tree, if you’re looking for values between 40 and 100:</p><ul><li>You just have to look for 40 (or the closest value after 40 if 40 doesn’t exist) like you did with the previous tree.</li><li>Then gather the successors of 40 using the direct links to the successors until you reach 100.</li></ul></blockquote><p>有了B+树后，如果你想取出所有40～100的值：</p><ul><li>你只需要像之前一样找到40(如果40不在，则找到第一个比40大的)</li><li>然后直接在有序链表中一直遍历到第一个大于100的节点结束</li></ul><blockquote><p>Let’s say you found M successors and the tree has N nodes. The search for a specific node costs log(N) like the previous tree. But, once you have this node, you get the M successors in M operations with the links to their successors. This search only costs M + log(N) operations vs N operations with the previous tree. Moreover, you don’t need to read the full tree (just M + log(N) nodes), which means less disk usage. If M is low (like 200 rows) and N large (1 000 000 rows) it makes a BIG difference.</p></blockquote><p>不妨假设有M个符合条件的节点并且树一共有N个节点。
在树中找到一个特定节点需要进行 log(N) 次操作。
但是找到这个节点后只需要进行M次操作就能完成这次查询。
总开销是M+log(N)，而在之前的树中需要进行N次操作。
除此之外，你不需要讲整棵树都读到内存中(只需要读M+log(N)个节点)，在磁盘IO上开销更小。
如果M相对较小(e.g.200)，N相对很大(e.g. 1 000 000)，二者的查询效率差距很大。</p><blockquote><p>But there are new problems (again!). If you add or remove a row in a database (and therefore in the associated B+Tree index):</p><ul><li>you have to keep the order between nodes inside the B+Tree otherwise you won’t be able to find nodes inside the mess.</li><li>you have to keep the lowest possible number of levels in the B+Tree otherwise the time complexity in O(log(N)) will become O(N).</li></ul></blockquote><p>但这样又有问题了。你在数据库中进行插入或删除的时候(会影响到相应的B+树索引)：</p><ul><li>你必须保持B+树中节点的有序性</li><li>你必须使B+树的层级尽可能的低，不然时间复杂度又会变成O(N)。</li></ul><blockquote><p>In other words, the B+Tree needs to be self-ordered and self-balanced. Thankfully, this is possible with smart deletion and insertion operations. But this comes with a cost: the insertion and deletion in a B+Tree are in O(log(N)). This is why some of you have heard that using too many indexes is not a good idea. Indeed, you’re slowing down the fast insertion/update/deletion of a row in a table since the database needs to update the indexes of the table with a costly O(log(N)) operation per index. Moreover, adding indexes means more workload for the transaction manager (we will see this manager at the end of the article).</p></blockquote><p>换言之，B+树需要是自排序和自平衡的。
值得庆幸的是，通过一种巧妙的插入、删除操作是可以做到的。
但是这对于写操作来说引入了额外的开销：在B+树中的插入和删除操作是O(log(N))的。
这就是为什么你有时候会听到 <strong>建太多索引不太好</strong> 。
确实，建立索引的代价是 <strong>拖慢对行的写操作</strong>，因为对表的更新需要同步到索引中。
除此之外，加索引会对 <strong>事务管理器</strong> 带来更多的负担。</p><blockquote><p>For more details, you can look at the Wikipedia article about B+Tree. If you want an example of a B+Tree implementation in a database, look at this article and this article from a core developer of MySQL. They both focus on how innoDB (the engine of MySQL) handles indexes.</p></blockquote><p>更多的细节可以查看这篇关于B+树的<a href=https://en.wikipedia.org/wiki/B%2B_tree target=_blank rel="noopener noreffer">Wikipedia</a>。
如果你想要了解B+树在数据库中的具体实现样例，可以看看<a href=https://blog.jcole.us/2013/01/07/the-physical-structure-of-innodb-index-pages/ target=_blank rel="noopener noreffer">这篇</a>和<a href=https://blog.jcole.us/2013/01/10/btree-index-structures-in-innodb/ target=_blank rel="noopener noreffer">这篇</a>文章，都出自MySQL的核心开发人员。
两篇文章聚焦于innoDB(MySQL的存储引擎)如何处理索引。</p><blockquote><p>Note: I was told by a reader that, because of low-level optimizations, the B+Tree needs to be fully balanced.</p></blockquote><p>注：曾经有读者和我说，因为底层优化，B+树需要完全平衡。</p><h3 id=133-哈希表>1.3.3 哈希表</h3><blockquote><p>Our last important data structure is the hash table. It’s very useful when you want to quickly look for values. Moreover, understanding the hash table will help us later to understand a common database join operation called the hash join. This data structure is also used by a database to store some internal stuff (like the lock table or the buffer pool, we’ll see both concepts later)</p></blockquote><p>最后一个比较重要的数据结构是哈希表。
它在想快速查找值的时候十分有用。
除此之外，理解哈希表能帮助我们之后理解 <strong>哈希联结</strong>。
这个数据结构同样也被数据库用于存储一些内部数据(例如 <strong>锁表</strong> 和 <strong>缓冲池</strong>，之后会谈到这些概念)</p><blockquote><p>The hash table is a data structure that quickly finds an element with its key. To build a hash table you need to define:
a key for your elements
a hash function for the keys. The computed hashes of the keys give the locations of the elements (called buckets).
a function to compare the keys. Once you found the right bucket you have to find the element you’re looking for inside the bucket using this comparison.</p></blockquote><p>哈希表是一个能通过键快速查询到值的数据结构。
为了建立一个哈希表你需要定义：</p><ul><li>元素的 <strong>键</strong></li><li>对键进行哈希的 <strong>哈希函数</strong>。哈希函数能够对输入的键计算出其在桶中的位置。</li><li><strong>一个用于比较键的函数</strong>。一旦找到相应的桶之后，需要利用这个函数来在桶中找到想要的元素。</li></ul><blockquote><p>A simple example
Let’s have a visual example:
举个例子：<figure><a class=lightgallery href=/images/hash_table.png title=/images/hash_table.png data-thumbnail=/images/hash_table.png data-sub-html="<h2>哈希表</h2>"><img class=lazyload src=/svg/loading.min.svg data-src=/images/hash_table.png data-srcset="/images/hash_table.png, /images/hash_table.png 1.5x, /images/hash_table.png 2x" data-sizes=auto alt=/images/hash_table.png height=500 width=500></a><figcaption class=image-caption>哈希表</figcaption></figure></p></blockquote><blockquote><p>This hash table has 10 buckets. Since I’m lazy I only drew 5 buckets but I know you’re smart so I let you imagine the 5 others. The Hash function I used is the modulo 10 of the key. In other words I only keep the last digit of the key of an element to find its bucket:</p><ul><li>if the last digit is 0 the element ends up in the bucket 0,</li><li>if the last digit is 1 the element ends up in the bucket 1,</li><li>if the last digit is 2 the element ends up in the bucket 2,</li><li>…</li></ul></blockquote><p>这个哈希表有 10 个桶。
因为我比较懒所以只画了 5 个桶但我知道你们很聪明所以能够想象出其余的 5 个桶。
这里的哈希函数是对键模 10。
换言之通过键的最后一位来找到相应的桶：</p><ul><li>如果最后一位是 0，那就落入 0 号桶</li><li>如果最后一位是 1，就落入 1 号桶</li><li>以此类推</li></ul><blockquote><p>The compare function I used is simply the equality between 2 integers.</p></blockquote><p>使用的比较函数就是对整数进行大小比较的方法。</p><blockquote><p>Let’s say you want to get the element 78:</p><ul><li>The hash table computes the hash code for 78 which is 8.</li><li>It looks in the bucket 8, and the first element it finds is 78.</li><li>It gives you back the element 78</li><li>The search only costs 2 operations (1 for computing the hash value and the other for finding the element inside the bucket).</li></ul></blockquote><p>以查找 78 为例：</p><ul><li>哈希表计算出 78 的哈希值是 8</li><li>查询 8 号桶，第一个元素就是 78</li><li>因此返回 78</li><li>这次查询仅执行了 2 次操作(一次用于计算哈希值，另一次用于在桶中找到元素)</li></ul><blockquote><p>Now, let’s say you want to get the element 59:</p><ul><li>The hash table computes the hash code for 59 which is 9.</li><li>It looks in the bucket 9, and the first element it finds is 99. Since 99!=59, element 99 is not the right element.</li><li>Using the same logic, it looks at the second element (9), the third (79), … , and the last (29).</li><li>The element doesn’t exist.</li><li>The search costs 7 operations.</li></ul></blockquote><p>现在来找 59</p><ul><li>59 的哈希值是 9</li><li>到 9 号桶进行查找，第一个元素是 99，因为 99!=59，所以 99 不是想要的元素</li><li>使用相同的逻辑在桶中继续查找，9 -> 79 -> 29&mldr;</li><li>遍历完整个桶发现也没有符合条件的，证明元素不存在</li><li>总共执行了 7 次</li></ul><blockquote><p>A good hash function</p></blockquote><p><strong>一个好的哈希函数</strong></p><blockquote><p>As you can see, depending on the value you’re looking for, the cost is not the same!</p></blockquote><p>如你所见，对于不同的值的查询开销并不相同。</p><blockquote><p>If I now change the hash function with the modulo 1 000 000 of the key (i.e. taking the last 6 digits), the second search only costs 1 operation because there are no elements in the bucket 000059. The real challenge is to find a good hash function that will create buckets that contain a very small amount of elements.</p></blockquote><p>如果我将哈希函数改为对键模1 000 000，第二次查找就只需要 1 次操作，因为 000059 号桶中没东西。
<strong>真正的困难点在于找到一个好的哈希函数，这个哈希函数需要保证在每个桶中的元素的量相当小。</strong></p><blockquote><p>In my example, finding a good hash function is easy. But this is a simple example, finding a good hash function is more difficult when the key is:</p><ul><li>a string (for example the last name of a person)</li><li>2 strings (for example the last name and the first name of a person)</li><li>2 strings and a date (for example the last name, the first name and the birth date of a person)</li><li>…</li></ul></blockquote><p>在我举的例子中找到一个好的哈希函数很简单。但这只是一个简单的示例，当键是如下类型的时候找到一个好的哈希函数就难得多了：</p><ul><li>一个字符串(例如一个人的姓)</li><li>两个字符串(例如一个人的姓和名)</li><li>两个字符串以及一个日期(例如姓、名、出生日期)</li></ul><blockquote><p>With a good hash function, the search in a hash table is in O(1).</p></blockquote><p><strong>在你有一个好的哈希函数的时候，在哈希表中查询的复杂度是O(1).</strong></p><blockquote><p>Array vs hash table</p></blockquote><p><strong>数组和哈希表对比</strong></p><blockquote><p>Why not using an array?</p></blockquote><p>为什么不用数组呢？</p><blockquote><p>Hum, you’re asking a good question.</p><ul><li>A hash table can be half loaded in memory and the other buckets can stay on disk.</li><li>With an array you have to use a contiguous space in memory. If you’re loading a large table it’s very difficult to have enough contiguous space.</li><li>With a hash table you can choose the key you want (for example the country AND the last name of a person).</li></ul></blockquote><p>这其实是一个好问题。</p><ul><li>一个哈希表在使用的时候并不需要全部读入内存。</li><li>使用数组的时候你需要在内存中有一块连续的空间，如果你需要将一张很大的表读入内存的话，很难找到这么大一块连续空间</li><li>使用哈希表你可以自己选择键的形式</li></ul><blockquote><p>For more information, you can read my article on the Java HashMap which is an efficient hash table implementation; you don’t need to understand Java to understand the concepts inside this article.</p></blockquote><p>如果你想要了解更多信息，可以读一下我这篇关于<a href=http://coding-geek.com/how-does-a-hashmap-work-in-java/ target=_blank rel="noopener noreffer">Java HashMap</a>实现的文章；读这篇文章不需要会Java就能理解其中的概念。</p><h1 id=2-全局概述>2 全局概述</h1><h1 id=3-客户端管理>3 客户端管理</h1><h1 id=4-查询管理>4 查询管理</h1><h2 id=41-查询解析>4.1 查询解析</h2><h2 id=42-查询重写>4.2 查询重写</h2><h2 id=43-统计信息>4.3 统计信息</h2><h2 id=44-查询优化器>4.4 查询优化器</h2><h3 id=441-索引>4.4.1 索引</h3><h3 id=442-访问路径>4.4.2 访问路径</h3><h3 id=443-联结操作>4.4.3 联结操作</h3><h3 id=444-简化的案例>4.4.4 简化的案例</h3><h3 id=445-动态规划贪心算法和启发式>4.4.5 动态规划、贪心算法和启发式</h3><h3 id=446-真正的优化器unimportant-part>4.4.6 真正的优化器(unimportant part)</h3><h3 id=447-查询计划缓存>4.4.7 查询计划缓存</h3><h2 id=45-查询执行>4.5 查询执行</h2><h1 id=5-数据管理>5 数据管理</h1><h2 id=51-缓存管理>5.1 缓存管理</h2><h3 id=511-预取>5.1.1 预取</h3><h3 id=512-缓存替换策略>5.1.2 缓存替换策略</h3><h3 id=513-写缓存>5.1.3 写缓存</h3><h2 id=52-事务管理>5.2 事务管理</h2><h3 id=521-酸了>5.2.1 酸了</h3><h3 id=522-并发控制>5.2.2 并发控制</h3><h3 id=523-锁管理>5.2.3 锁管理</h3><h3 id=524-日志管理>5.2.4 日志管理</h3><h1 id=6-总结>6 总结</h1></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>更新于 2022-05-12</span></div><div class=post-info-license></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/db/>db</a>,&nbsp;<a href=/tags/rdbms/>rdbms</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/posts/cmu15445-db-storage/ class=prev rel=prev title=[note]数据库存储><i class="fas fa-angle-left fa-fw"></i>[note]数据库存储</a></div></div><div id=comments><div id=gitalk class=comment></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://github.com/gitalk/gitalk></a>Gitalk</a>.</noscript></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line>由 <a href=https://gohugo.io/ target=_blank rel="noopener noreffer" title="Hugo 0.98.0">Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/dillonzq/LoveIt target=_blank rel="noopener noreffer" title="LoveIt 0.2.10"><i class="far fa-kiss-wink-heart fa-fw"></i> LoveIt</a></div><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2022</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank>zh</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title=回到顶部><i class="fas fa-arrow-up fa-fw"></i>
</a><a href=# id=view-comments class=fixed-button title=查看评论><i class="fas fa-comment fa-fw"></i></a></div><link rel=stylesheet href=/lib/gitalk/gitalk.min.css><link rel=stylesheet href=/lib/katex/katex.min.css><link rel=stylesheet href=/lib/katex/copy-tex.min.css><link rel=stylesheet href=/css/befdf6.min.css><script type=text/javascript src=/lib/gitalk/gitalk.min.js></script><script type=text/javascript src=/lib/smooth-scroll/smooth-scroll.min.js></script><script type=text/javascript src=/lib/lazysizes/lazysizes.min.js></script><script type=text/javascript src=/lib/clipboard/clipboard.min.js></script><script type=text/javascript src=/lib/sharer/sharer.min.js></script><script type=text/javascript src=/lib/katex/katex.min.js></script><script type=text/javascript src=/lib/katex/auto-render.min.js></script><script type=text/javascript src=/lib/katex/copy-tex.min.js></script><script type=text/javascript src=/lib/katex/mhchem.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"复制到剪贴板",maxShownLines:10},comment:{gitalk:{admin:["rustzzh"],clientID:"da0c5fc5ea73e5fd68b1",clientSecret:"b109d474223d93fb730ca7e01f2b4d0d63fcc60d",id:"2022-05-09T17:35:56+08:00",owner:"rustzzh",repo:"rustzzh.github.io",title:"[tran]关系型数据库原理"}},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1}}</script><script type=text/javascript src=/js/theme.min.js></script></body></html>